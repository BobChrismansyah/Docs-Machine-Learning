{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Docs Machine Learning \u00b6 Dokumentasi ini dibuat dari hasil Googling, Github AI, dan buku pengenalan Machine Learning graph LR A[Machine Learning] --> B[Supervised Learning] A --> C[Unsupervised Learning] A --> D[Reinforcement Learning] A --> E[Semi-Supervised Learning] B --> F[Regression] B --> G[Classification] B --> H[Deep Learning] F --> I[Linear] F --> J[Polynomial] G --> K[Logistic Regression] G --> L[Decision Tree] G --> M[SVM] G --> N[ANN] H --> O[CNN] H --> P[<a href='#'>RNN</a>] C --> Q[Clustering] Q --> R[K-Means] C --> U[Dimensionality Reduction] U --> T[PCA] C --> S[Anomaly Detection] E --> V[Self Training] E --> W[Low-density Separation] D --> X[Dynaics Programming] D --> Y[Monte Carlo Methods] Kami TIDAK bertanggung-jawab atas KEAKURATAN mau pun KERUGIAN yang mungkin terjadi akibat memanfaatkan situs ini. HARAP MENANGGUNG SENDIRI SEGALA RISIKO! Jangan lupa mengungkapkan/ menuliskan penghargaan (acknowledgement) jika anda menggunakan bahan karya dari pihak lain. Situs ini berbasis \u201cGoogle Sana, Google Sini, Coba Itu, Coba Ini, Lalu Tanya-tanyi\u201d (GSGSCICILTT). Entah ini PLAGIAT, entah ini RISET, yang jelas tidak pernah ada klaim bahwa ini merupakan karya asli, serta belum tentu pula merupakan solusi terbaik, serta bukan untuk konsumsi Scopus :). Mohon kiranya memberikan tanggapan, terutama jika memiliki solusi alternatif. Semoga catatan ini akan bermanfaat di masa mendatang, saat sudah lupa cara menyelesaikan masalah trivia ini. Rahmat M. Samik-Ibrahim Kontribusi \u00b6 Jika menemukan kesalahan dalam penulisan kata atau ingin menambahkan konten baru, silahkan buat perubahan. Anda juga bisa menggunakan tombol dibagian kanan atas di setiap artikel/konten untuk menambahkan ke pull request. Jika tidak tau apa maksudnya, anda juga bisa membuat issue atau kirim email. Terima Kasih \u00b6","title":"Docs"},{"location":"#docs-machine-learning","text":"Dokumentasi ini dibuat dari hasil Googling, Github AI, dan buku pengenalan Machine Learning graph LR A[Machine Learning] --> B[Supervised Learning] A --> C[Unsupervised Learning] A --> D[Reinforcement Learning] A --> E[Semi-Supervised Learning] B --> F[Regression] B --> G[Classification] B --> H[Deep Learning] F --> I[Linear] F --> J[Polynomial] G --> K[Logistic Regression] G --> L[Decision Tree] G --> M[SVM] G --> N[ANN] H --> O[CNN] H --> P[<a href='#'>RNN</a>] C --> Q[Clustering] Q --> R[K-Means] C --> U[Dimensionality Reduction] U --> T[PCA] C --> S[Anomaly Detection] E --> V[Self Training] E --> W[Low-density Separation] D --> X[Dynaics Programming] D --> Y[Monte Carlo Methods] Kami TIDAK bertanggung-jawab atas KEAKURATAN mau pun KERUGIAN yang mungkin terjadi akibat memanfaatkan situs ini. HARAP MENANGGUNG SENDIRI SEGALA RISIKO! Jangan lupa mengungkapkan/ menuliskan penghargaan (acknowledgement) jika anda menggunakan bahan karya dari pihak lain. Situs ini berbasis \u201cGoogle Sana, Google Sini, Coba Itu, Coba Ini, Lalu Tanya-tanyi\u201d (GSGSCICILTT). Entah ini PLAGIAT, entah ini RISET, yang jelas tidak pernah ada klaim bahwa ini merupakan karya asli, serta belum tentu pula merupakan solusi terbaik, serta bukan untuk konsumsi Scopus :). Mohon kiranya memberikan tanggapan, terutama jika memiliki solusi alternatif. Semoga catatan ini akan bermanfaat di masa mendatang, saat sudah lupa cara menyelesaikan masalah trivia ini. Rahmat M. Samik-Ibrahim","title":"Docs Machine Learning"},{"location":"#kontribusi","text":"Jika menemukan kesalahan dalam penulisan kata atau ingin menambahkan konten baru, silahkan buat perubahan. Anda juga bisa menggunakan tombol dibagian kanan atas di setiap artikel/konten untuk menambahkan ke pull request. Jika tidak tau apa maksudnya, anda juga bisa membuat issue atau kirim email.","title":"Kontribusi"},{"location":"#terima-kasih","text":"","title":"Terima Kasih"},{"location":"about/","text":"","title":"About"},{"location":"docs/","text":"","title":"Index"},{"location":"docs/churn-prediction/","text":"","title":"Churn Prediction"},{"location":"docs/clustering/","text":"","title":"Clustering"},{"location":"docs/decision-tree/","text":"","title":"Decision Tree"},{"location":"docs/logistic-regression/","text":"","title":"Logistic Regression"},{"location":"docs/naive-bayes/","text":"","title":"Naive Bayes"},{"location":"docs/neural-network/","text":"Neural network \u00b6 Multi Layer Perceptron \u00b6 Multi layer perception adalah salah satu jenis neural network yang paling umum digunakan. Multi layer perception terdiri dari 3 layer, yaitu input layer, hidden layer, dan output layer. Input layer merupakan layer pertama yang menerima input dari data. Hidden layer merupakan layer yang berada di tengah-tengah antara input layer dan output layer. Output layer merupakan layer terakhir yang menghasilkan output dari data. Yang perlu diperhatikan adalah setiap node dalam dsatu lapisan akan tersambung secara penuh ke semua node di lapisan berikutnya. Informasi yang mengalir dalam satu arah yaitu dari kiri ke kanan yang disebut dengan jaringan feedforward . Hubungan antara node juga akan diberikan angka bobot masing-masing yang menentukan seberapa penting feature yang bersangkutan. Jika ada 10 feature maka akan ada 10 input node. Multi Layer Perceptron: flowchart LR id1[(Data)] --> id2[Input Layer] id1 --> id3[Hidden Layer] id1 --> id4[Output Layer] subgraph Input Layer id2((X1)) id3((X2)) id4((X3)) end id2 --> id5 id2 --> id6 id3 --> id5 id3 --> id6 id4 --> id5 id4 --> id6 subgraph Hidden Layer id5((H1)) id6((H2)) end id5 --> id7 id6 --> id7 subgraph Output Layer id7((Y)) end id7 --> output Jumlah Hiden Layer bergantung pada seberapa kopmleks pembelajaran yang mau ditentukan. Semakin kompleks pembelajaran maka semakin banyak hidden layer yang dibutuhkan. Jumlah hidden layer juga bergantung pada jumlah node yang ada di dalamnya. Semakin banyak node maka semakin kompleks pembelajaran yang bisa dilakukan. Jumlah node juga bergantung pada jumlah feature yang ada. Semakin banyak feature maka semakin banyak node yang dibutuhkan. Jumlah node juga bergantung pada jumlah output yang diinginkan. Semakin banyak output yang diinginkan maka semakin banyak node yang dibutuhkan. Deep Learning menggunakan Multi Layer Perceptron dengan jumlah hidden layer yang sangat banyak. Jumlah hidden layer yang banyak akan membuat pembelajaran menjadi lebih kompleks. Semakin kompleks pembelajaran maka semakin baik hasil prediksi yang dihasilkan. Cara Membangun Model MLP \u00b6 MLP adalah metode supervised learning oleh sebab itu membutuhkan label di training dataset . Langkah selanjutnyta adalah melakukan training dengan mekanisme interatif yang disebut dengan backpropagation , yang bisa dianalogikan proses bejalar dari kesalahan. Proses backpropagation akan menghitung error dari setiap node dan mengubah bobot dari setiap node agar error semakin kecil. Proses backpropagation akan berhenti jika error sudah sangat kecil atau sudah mencapai batas maksimal iterasi yang ditentukan. Contoh Implementasi MLP \u00b6 Penggunaan MLP dengan menggunakan library scikit-learn. Berikut adalah contoh implementasi MLP dengan menggunakan library scikit-learn. from sklearn.neural_network import MLPClassifier from sklearn.model_selection import train_test_split Metode ini bisa digunakan untuk klasifikasi dan regresi. Untuk klasifikasi, MLPClassifier menggunakan fungsi aktivasi logistic untuk output layer. Untuk regresi, MLPRegressor menggunakan fungsi aktivasi identity untuk output layer. Untuk klasifikasi, MLPClassifier menggunakan fungsi aktivasi logistic untuk output layer. Untuk regresi, MLPRegressor menggunakan fungsi aktivasi identity untuk output layer. Import semua modul yang kita perlukan seperti Pandaas, Neural Network dan model_selection import pandas as pd import sklearn.neural_network as ann import sklearn.model_selection as ms df_occupancy = pd . read_csv ( 'datatraining.csv' , header = 0 , names = [ \"id\" , \"date\" , \"Temperature\" , \"Humadity\" , \"Light\" , \"CO2\" , \"HumadityRatio\" , \"Occupancy\" ]) Kemudian buang id dan date karena tidak diperlukan untuk proses training X = df_occupancy . drop ([ 'id' , 'date' ], axis = 1 ) y = df_occupancy [ 'Occupancy' ] kemudian dilakukan profiling singkat dari kelima feature tersebut X . describe () Ada 8.143 baris data, perbedaan antara nilai maksimum dan minimum cukup besar, misalnya suhu dari 19 hingga 23, cahaya memiliki jangkauan dari nol hingga 1.546 sehinga perbedaannya cukup besar, sedangkan MLP sangat sensitif terhadap dengan perbedaan seperti ini (lain halnya dengan algoritma Decision Tree atau Naive Bayes). Untuk itu, kita perlu melakukan normalisasi terhadap data-data tersebut. Sebelum proses training dilakukan, kita perlu membagi data menjadi dua bagian, yaitu data training dan data testing. Data training digunakan untuk proses training, sedangkan data testing digunakan untuk menguji akurasi dari model yang kita buat. Untuk membagi data, kita bisa menggunakan fungsi train_test_split dari modul model_selection yang sudah kita import sebelumnya. X_train , X_test , y_train , y_test = ms . train_test_split ( X , y , test_size = 0.2 ) X_train . count ()","title":"Neural Network"},{"location":"docs/neural-network/#neural-network","text":"","title":"Neural network"},{"location":"docs/neural-network/#multi-layer-perceptron","text":"Multi layer perception adalah salah satu jenis neural network yang paling umum digunakan. Multi layer perception terdiri dari 3 layer, yaitu input layer, hidden layer, dan output layer. Input layer merupakan layer pertama yang menerima input dari data. Hidden layer merupakan layer yang berada di tengah-tengah antara input layer dan output layer. Output layer merupakan layer terakhir yang menghasilkan output dari data. Yang perlu diperhatikan adalah setiap node dalam dsatu lapisan akan tersambung secara penuh ke semua node di lapisan berikutnya. Informasi yang mengalir dalam satu arah yaitu dari kiri ke kanan yang disebut dengan jaringan feedforward . Hubungan antara node juga akan diberikan angka bobot masing-masing yang menentukan seberapa penting feature yang bersangkutan. Jika ada 10 feature maka akan ada 10 input node. Multi Layer Perceptron: flowchart LR id1[(Data)] --> id2[Input Layer] id1 --> id3[Hidden Layer] id1 --> id4[Output Layer] subgraph Input Layer id2((X1)) id3((X2)) id4((X3)) end id2 --> id5 id2 --> id6 id3 --> id5 id3 --> id6 id4 --> id5 id4 --> id6 subgraph Hidden Layer id5((H1)) id6((H2)) end id5 --> id7 id6 --> id7 subgraph Output Layer id7((Y)) end id7 --> output Jumlah Hiden Layer bergantung pada seberapa kopmleks pembelajaran yang mau ditentukan. Semakin kompleks pembelajaran maka semakin banyak hidden layer yang dibutuhkan. Jumlah hidden layer juga bergantung pada jumlah node yang ada di dalamnya. Semakin banyak node maka semakin kompleks pembelajaran yang bisa dilakukan. Jumlah node juga bergantung pada jumlah feature yang ada. Semakin banyak feature maka semakin banyak node yang dibutuhkan. Jumlah node juga bergantung pada jumlah output yang diinginkan. Semakin banyak output yang diinginkan maka semakin banyak node yang dibutuhkan. Deep Learning menggunakan Multi Layer Perceptron dengan jumlah hidden layer yang sangat banyak. Jumlah hidden layer yang banyak akan membuat pembelajaran menjadi lebih kompleks. Semakin kompleks pembelajaran maka semakin baik hasil prediksi yang dihasilkan.","title":"Multi Layer Perceptron"},{"location":"docs/neural-network/#cara-membangun-model-mlp","text":"MLP adalah metode supervised learning oleh sebab itu membutuhkan label di training dataset . Langkah selanjutnyta adalah melakukan training dengan mekanisme interatif yang disebut dengan backpropagation , yang bisa dianalogikan proses bejalar dari kesalahan. Proses backpropagation akan menghitung error dari setiap node dan mengubah bobot dari setiap node agar error semakin kecil. Proses backpropagation akan berhenti jika error sudah sangat kecil atau sudah mencapai batas maksimal iterasi yang ditentukan.","title":"Cara Membangun Model MLP"},{"location":"docs/neural-network/#contoh-implementasi-mlp","text":"Penggunaan MLP dengan menggunakan library scikit-learn. Berikut adalah contoh implementasi MLP dengan menggunakan library scikit-learn. from sklearn.neural_network import MLPClassifier from sklearn.model_selection import train_test_split Metode ini bisa digunakan untuk klasifikasi dan regresi. Untuk klasifikasi, MLPClassifier menggunakan fungsi aktivasi logistic untuk output layer. Untuk regresi, MLPRegressor menggunakan fungsi aktivasi identity untuk output layer. Untuk klasifikasi, MLPClassifier menggunakan fungsi aktivasi logistic untuk output layer. Untuk regresi, MLPRegressor menggunakan fungsi aktivasi identity untuk output layer. Import semua modul yang kita perlukan seperti Pandaas, Neural Network dan model_selection import pandas as pd import sklearn.neural_network as ann import sklearn.model_selection as ms df_occupancy = pd . read_csv ( 'datatraining.csv' , header = 0 , names = [ \"id\" , \"date\" , \"Temperature\" , \"Humadity\" , \"Light\" , \"CO2\" , \"HumadityRatio\" , \"Occupancy\" ]) Kemudian buang id dan date karena tidak diperlukan untuk proses training X = df_occupancy . drop ([ 'id' , 'date' ], axis = 1 ) y = df_occupancy [ 'Occupancy' ] kemudian dilakukan profiling singkat dari kelima feature tersebut X . describe () Ada 8.143 baris data, perbedaan antara nilai maksimum dan minimum cukup besar, misalnya suhu dari 19 hingga 23, cahaya memiliki jangkauan dari nol hingga 1.546 sehinga perbedaannya cukup besar, sedangkan MLP sangat sensitif terhadap dengan perbedaan seperti ini (lain halnya dengan algoritma Decision Tree atau Naive Bayes). Untuk itu, kita perlu melakukan normalisasi terhadap data-data tersebut. Sebelum proses training dilakukan, kita perlu membagi data menjadi dua bagian, yaitu data training dan data testing. Data training digunakan untuk proses training, sedangkan data testing digunakan untuk menguji akurasi dari model yang kita buat. Untuk membagi data, kita bisa menggunakan fungsi train_test_split dari modul model_selection yang sudah kita import sebelumnya. X_train , X_test , y_train , y_test = ms . train_test_split ( X , y , test_size = 0.2 ) X_train . count ()","title":"Contoh Implementasi MLP"},{"location":"docs/pandas/","text":"Dasar-Dasar Pandas \u00b6 Langkah pertama yang harus dilakukan yaitu mengimpor library pandas: import pandas as pd Untuk mempermudah, kita akan menggunakan pd sebagai alias dari pandas. Konspep pandas yaitu menyimpan data yang disebut Series dan DataFrame . Series adalah kolom tunggal, sedangkan DataFrame adalah tabel yang terdiri dari beberapa kolom atau series. Series: \u00b6 mangga 0 1 1 2 2 3 mangga = pd . Series ([ 1 , 2 , 3 ]) Pandas akan otomatis membuat index untuk series, jika tidak ingin menggunakan index default, kita bisa menambahkan parameter index: mangga = pd . Series ([ 1 , 2 , 3 ], index = [ 'a' , 'b' , 'c' ]) Index tidak harus berupa angka numerik, bisa kita ganti dengan string. Dataframe \u00b6 DataFrame tidak jauh beda dengan array NumPy yaitu berupa tabel dua dimensi dengan baris dan kolom. Cara membuat DataFrame adalah dengan menggunakan dictionary: df1 = pd . DataFrame ({ 3 , 0 , 9 }), columns = [ 'apel' ], index = [ 1 , 2 , 3 ]) apel 1 3 2 0 3 9 Untuk DataFrame dengan dua kolom, kita bisa menggunakan dictionary dengan dua key: dict1 = { 'apel' : [ 3 , 0 , 9 ], 'jeruk' : [ 1 , 4 , 2 ]} df1 = pd . DataFrame ( dict1 ) apel jeruk 0 3 1 1 0 4 2 9 2 Setelah DataFrame terbentuk kita bebas memanipulasinya. Menghitung jumlah data dengan fungsi count() dan juga menghitung jumlah keseluruhan semua nilai sum() df1 . count () Output apel 3 jeruk 3 dtype: int64","title":"Pandas"},{"location":"docs/pandas/#dasar-dasar-pandas","text":"Langkah pertama yang harus dilakukan yaitu mengimpor library pandas: import pandas as pd Untuk mempermudah, kita akan menggunakan pd sebagai alias dari pandas. Konspep pandas yaitu menyimpan data yang disebut Series dan DataFrame . Series adalah kolom tunggal, sedangkan DataFrame adalah tabel yang terdiri dari beberapa kolom atau series.","title":"Dasar-Dasar Pandas"},{"location":"docs/pandas/#series","text":"mangga 0 1 1 2 2 3 mangga = pd . Series ([ 1 , 2 , 3 ]) Pandas akan otomatis membuat index untuk series, jika tidak ingin menggunakan index default, kita bisa menambahkan parameter index: mangga = pd . Series ([ 1 , 2 , 3 ], index = [ 'a' , 'b' , 'c' ]) Index tidak harus berupa angka numerik, bisa kita ganti dengan string.","title":"Series:"},{"location":"docs/pandas/#dataframe","text":"DataFrame tidak jauh beda dengan array NumPy yaitu berupa tabel dua dimensi dengan baris dan kolom. Cara membuat DataFrame adalah dengan menggunakan dictionary: df1 = pd . DataFrame ({ 3 , 0 , 9 }), columns = [ 'apel' ], index = [ 1 , 2 , 3 ]) apel 1 3 2 0 3 9 Untuk DataFrame dengan dua kolom, kita bisa menggunakan dictionary dengan dua key: dict1 = { 'apel' : [ 3 , 0 , 9 ], 'jeruk' : [ 1 , 4 , 2 ]} df1 = pd . DataFrame ( dict1 ) apel jeruk 0 3 1 1 0 4 2 9 2 Setelah DataFrame terbentuk kita bebas memanipulasinya. Menghitung jumlah data dengan fungsi count() dan juga menghitung jumlah keseluruhan semua nilai sum() df1 . count () Output apel 3 jeruk 3 dtype: int64","title":"Dataframe"}]}